# Deep-Learning-Project

In this project, three LSMT language models have been trained on each of their data. 
The model trained on the Penn Treebank data set has been used for comparison reasons and has shown to reach a validation perplexity of 88.2. The same hyperparameters were used for the other data sets, however did not show the desired performance. Importantly, these data sets had no benchmarks.

The data folder holds the data used for text generation, that is storylines for Kim Possible and text from the first three Harry Potter books. 

The data for PTB is downloaded from: 
https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt
https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt
https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt
